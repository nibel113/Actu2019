# Preuves 

##Théorème (\@ref(thm:fn-quantile)) de la fonction quantile 
\label{preuves:fn-quantile}
```{proof}
\begin{align*}
F_{F_x^{-1}(u)}(x)& =P(F_X^{-1} \le x)\\
& =P(U \le F_X(x))\\
& =F_X(x)
\end{align*}
```

##Fonction Stop-Loss(\@ref(intro:fn-stop))
\label{preuves:fn-stop}
```{proof}
\begin{align*}
\Pi_X(d)& = E[\max(X-d, 0)]\\
& =E[X  \mathrm{1}_{ \{X > d\} } -d\times \mathrm{1}_{\{X > d\}}]\\
& =E[X \mathrm{1}_{\{X > d\}}]-d \bar{F}(d)\\
\end{align*}
```

##Tvar
###Expresion alternative 1(\@ref(intro:tvar:alt1)) 
\label{preuves:tvar:1}
```{proof}
On applique \@ref(intro:fn-quantile:1), ainsi:
\begin{align*}
\text{TVaR}_k(X)& =\frac{1}{(1-k)}\int_k^1\text{VaR}_k(u)\,du\\
& =\frac{1}{1-k}(\Pi_X(\text{VaR}_k(X)))+\text{VaR}_k(X)
\end{align*}
```

###Expression alternative 2(\@ref(intro:tvar:alt2))
\label{preuves:tvar:2}
```{proof}
On remplace $\Pi_X(\text{VaR}_k(X))$ dans \@ref(preuves:tvar:2) par sa définition \@ref(intro:fn-stop)
\begin{align*}
\text{TVaR}_k(X)& = \text{VaR}_k(X)+\frac{1}{(1-k)}(E[X\times\mathrm{1}_{\{X>\text{VaR}_k(X)\}}]-\text{VaR}_k(X)\bar{F}(\text{VaR}_k(X)))\\
& =\frac{1}{(1-k)}[E[X\times\mathrm{1}_{\{X>\text{VaR}_k(X)\}}]-\text{Var}_k(X)(\bar{F}_X(\text{VaR}_k(X))-(1-k))]\\
& =\frac{1}{(1-k)}[E[X\times\mathrm{1}_{\{X>\text{VaR}_k(X)\}}]-\text{Var}_k(X)(F_X(\text{VaR}_k(X))-k)]
\end{align*}
```
Pour une V.A. continue $\text{VaR}_k(X)(F_X(\text{VaR}_k(X))-k)=0$ donc,
$$\text{TVaR}_k(X)= \frac{E[X\times\mathrm{1}_{\{X>\text{VaR}_k(X)\}}]}{P(X>\text{VaR}_k(X))}= E[X|X>\text{VaR}_k(X)]$$

###Expression alternative 3(\@ref(intro:tvar:alt3))
\label{preuves:tvar:3}
On fait la preuve à partir de l'expression alternative 2:
```{proof}
\begin{align*}
\text{TVaR}_k(X)& =\frac{1}{(1-k)}[E[X\times\mathrm{1}_{\{X>\text{VaR}_k(X)\}}]-\text{Var}_k(X)(F_X(\text{VaR}_k(X))-k)]\\
& =\frac{1}{(1-k)}[E[X\times\mathrm{1}_{\{X>\text{VaR}_k(X)\}}+X\times\mathrm{1}_{\{X=\text{VaR}_k(X)\}}-X\times\mathrm{1}_{\{X=\text{VaR}_k(X)\}}]-\text{Var}_k(X)(1-\bar{F}_X(\text{VaR}_k(X))-(1-(1-k)))\\
& =\frac{1}{(1-k)}\{E[X\times\mathrm{1}_{\{X\ge\text{VaR}_k(X)\}}]-E[X\times\mathrm{1}_{\{X=\text{VaR}_k(X)\}}]+\text{VaR}_k(X)[(1-k)-P(X>\text{VaR}_k(X))]\}\\
& =\frac{1}{(1-k)}\{E[X\times\mathrm{1}_{\{X\ge\text{VaR}_k(X)\}}]-(E[X\times\mathrm{1}_{\{X=\text{VaR}_k(X)\}}]+P(X>\text{VaR}_k(X))\times\text{VaR}_k(X))\}
\end{align*}
Deux cas possibles: 
1)V.A. discrète $P(X=\text{VaR}_k(X))>0$ 
2)V.A. continue $P(X=\text{VaR}_k(X))=0$ 
Donc la portion $(E[X\times\mathrm{1}_{\{X=\text{VaR}_k(X)\}}]+P(X>\text{VaR}_k(X))\times\text{VaR}_k(X))=  \text{VaR}_k(X)[1-\frac{P(X\ge\text{VaR}_k(X))}{(1-k)}]$
```


##Biais moyenne échantillonale (voir \@ref(stats:criteres:biais))
\label{preuves:biais:xn}
```{proof}
\begin{gather*}
B(\hat{\theta}_n)=E[\bar{X}_n]-E[X]\\
=E[x]-E[X]=0
\end{gather*}
```

##Biais variance échantillonale (voir \@ref(stats:criteres:biais))
\label{preuves:biais:sn}
```{proof}
\begin{gather*}
S_n^2= \frac{1}{n-1}(\sum_{i=1}^n {(X_i-\bar{X}_n)}^2)\\
=\frac{1}{n-1}(\sum_{i=1}^n (X_i^2-2X_i\bar{X}_n+\bar{X}_n^2))\\
=\frac{1}{n-1}[(\sum_{i=1}^n X_i^2)  -\frac{2}{n-1}(\bar{X}_n\sum_{i=1}^n X_i) +\frac{n}{(n-1)}((\bar{X}_n)^2)]\\
= \frac{1}{n-1}(\sum_{i=1}^n X_i^2) - \frac{n}{(n-1)}(\bar{X}_n^2)
\end{gather*}

\begin{gather*}
E[S_n^2]=E[\frac{1}{n-1}(\sum_{i=1}^n)]-E[\frac{n}{(n-1)}(\bar{X}_n)]\\
=\frac{n}{n-1}((Var(X)+E^2[X])) - \frac{1}{(n-1)}(Var(X))-\frac{n}{n-1}(E[X^2])\\
=Var(X)
\end{gather*}

\begin{gather*}
B(S^2_n)= Var(X)-\sigma^2 = 0
\end{gather*}
```

##Convergence (voir \@ref(stats:convergence))
\label{preuves:convergence}
```{proof}
On prouve avec Tchebycheff  
Un estimateur sans biais est convergent si:
$$
\lim_{n\to \infty} Var(\hat{\theta}_n) =0
$$
\begin{gather*}
\text{On fixe}\; \epsilon>0,\\
P(|\hat{\theta}_n-\theta|>\epsilon)= P(|\hat{\theta}_n-E[\hat{\theta}_n]|>\epsilon)\\
=P(|\hat{\theta}_n-E[\hat{\theta}_n]|>\frac{\epsilon\times \sqrt{Var(\hat{\theta}_n)}}{\sqrt{Var(\hat{\theta}_n)}})\\
\le \frac{Var(\hat{\theta}_n)}{\epsilon^2}
\end{gather*}
Donc si $Var(\hat{\theta}_n)\to 0$ quand $n \to \infty$, $\hat{\theta}_n$ est convergent
```









